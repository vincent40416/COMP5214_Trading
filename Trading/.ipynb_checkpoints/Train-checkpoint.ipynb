{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm, trange\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from torch.optim.lr_scheduler import MultiplicativeLR\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Device Setting & data directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()\n",
    "data_dir = os.path.dirname(path)\n",
    "device = torch.device('cuda:0')\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading transformers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at activebus/BERT-DK_rest were not used when initializing BertModel: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load_transformer\n",
    "print('Loading transformers...')\n",
    "transformer_tag = \"activebus/BERT-DK_rest\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(transformer_tag)\n",
    "transformer = AutoModel.from_pretrained(transformer_tag, add_pooling_layer=False)\n",
    "transformer.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Combined_News_DJIA data...\n",
      "Loading upload_DJIA_table data...\n",
      "Loaded\n"
     ]
    }
   ],
   "source": [
    "def load_data(split_name='train'):\n",
    "    print('Loading {} data...'.format(split_name))\n",
    "    df = pd.read_csv(data_dir + f'/{split_name}.csv')\n",
    "    return df\n",
    "df = load_data('Combined_News_DJIA')\n",
    "stock_df = load_data('upload_DJIA_table')\n",
    "df['price'] = stock_df.Close\n",
    "\n",
    "train_df = df[:int(len(df) * 0.9)]\n",
    "valid_df = df[int(len(df) * 0.9):]\n",
    "num_train_batches = (len(train_df) + batch_size - 1) // batch_size\n",
    "num_valid_batches = (len(valid_df) + batch_size - 1) // batch_size\n",
    "# news = pd.read_csv(\"../Combined_News_DJIA.csv\")\n",
    "\n",
    "print(\"Loaded\")\n",
    "# train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model \n",
    "Pre_trained_BERT Finished <br>\n",
    "Need Linear & LSTM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, hidden_size, num_linear=1):\n",
    "        super(Model, self).__init__()\n",
    "        self.pooler = nn.Sequential(\n",
    "            nn.Linear(768, 768),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "        self.layers = nn.ModuleList([nn.Linear(768 + 1, hidden_size)])\n",
    "        self.layers.extend([nn.Linear(hidden_size, hidden_size) for i in range(num_linear)])\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.output = nn.Linear(hidden_size, 1)\n",
    "    def forward(self, text_embeddings, other_inputs):\n",
    "        pooled_output = self.pooler(text_embeddings)  # (batch_size, 768)\n",
    "        h = torch.cat([pooled_output, other_inputs], 1)  # (batch_size, 768 + 1)\n",
    "#         Add LSTM HERE\n",
    "# \n",
    "# \n",
    "        for layer in self.layers:\n",
    "            h = nn.functional.leaky_relu(layer(h))  # (batch_size, hidden_size)\n",
    "            h = self.dropout(h)\n",
    "        o = self.output(h)  # (batch_size, 1)\n",
    "        return o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "lr = 0.01\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "hidden_size = 128\n",
    "num_linear = 1\n",
    "\n",
    "records = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_predictions(outputs):\n",
    "    logits = torch.sigmoid(outputs)\n",
    "    threshold = 0.5\n",
    "    predictions = torch.zeros(len(logits),1).to(device)\n",
    "    for i in range(len(logits)):\n",
    "        if logits[i] < threshold:\n",
    "            predictions[i] = 0\n",
    "        else:\n",
    "            predictions[i] = 1\n",
    "    return predictions\n",
    "\n",
    "# Brute concatenate TopK News\n",
    "def make_input_batch(i_batch, df, batch_size):\n",
    "    rows = df[i_batch* batch_size : min((i_batch+1) * batch_size, len(df))]\n",
    "    text = rows[rows.columns.difference(['price', 'Label', 'Date'])]\n",
    "    text = text.apply(lambda x :' '.join(x.astype(str)),1).tolist()\n",
    "    text_inputs = tokenizer(text, padding='max_length', truncation=True, return_tensors=\"pt\")\n",
    "    text_inputs = {k : v.to(device) for k, v in text_inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        text_embeddings = transformer(**text_inputs, return_dict=True).last_hidden_state[:,0,:]\n",
    "    other_inputs = torch.tensor([rows.price.tolist()], dtype=torch.float32).to(device) # (batch_size, 1)\n",
    "    other_inputs = torch.transpose(other_inputs, 0, 1)\n",
    "    train_labels = torch.tensor([rows.Label.tolist()],dtype=torch.float32).to(device)  \n",
    "    train_labels = torch.transpose(train_labels, 0, 1) # (batch_size, 1)\n",
    "    return text_embeddings, other_inputs, train_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "ep  1:   0%|          | 0/28 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hid-128-numlin-1\n",
      "0\n",
      "Start Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "ep  1:   4%|▎         | 1/28 [00:03<01:43,  3.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0528,  0.1368,  0.3317,  ..., -0.1397,  0.2129,  0.0703],\n",
      "        [ 0.0669,  0.0609,  0.3438,  ..., -0.2793,  0.2101,  0.0338],\n",
      "        [-0.0527,  0.0516,  0.0574,  ..., -0.1062,  0.2186,  0.2217],\n",
      "        ...,\n",
      "        [-0.1044,  0.1968,  0.3347,  ..., -0.3156,  0.2320,  0.2724],\n",
      "        [-0.0208,  0.0211,  0.0596,  ..., -0.2565,  0.2270,  0.2994],\n",
      "        [ 0.0378,  0.1423,  0.1913,  ..., -0.3356,  0.3413,  0.3159]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 0.2056, -0.1079,  0.3447,  ..., -0.2117, -0.2746,  0.1264],\n",
      "        [ 0.2381, -0.0581,  0.2658,  ..., -0.2303, -0.3174, -0.0706],\n",
      "        [ 0.2331, -0.1598,  0.3548,  ..., -0.3596, -0.2658, -0.1136],\n",
      "        ...,\n",
      "        [ 0.1292, -0.0400,  0.1758,  ..., -0.1401, -0.3659,  0.0030],\n",
      "        [ 0.2233, -0.0077,  0.2368,  ..., -0.2051, -0.2201, -0.0569],\n",
      "        [ 0.1848, -0.0899,  0.2260,  ..., -0.3027, -0.2684, -0.0993]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward>)\n",
      "tensor(32.7403, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "ep  1:   7%|▋         | 2/28 [00:07<01:39,  3.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1594,  0.1761,  0.2423,  ..., -0.1152,  0.2215,  0.2846],\n",
      "        [ 0.0288,  0.1082,  0.2337,  ..., -0.2565,  0.1103,  0.1016],\n",
      "        [ 0.0245,  0.1386,  0.2352,  ..., -0.1961,  0.1942,  0.0708],\n",
      "        ...,\n",
      "        [ 0.0473,  0.1723,  0.2108,  ..., -0.3635,  0.2265,  0.2330],\n",
      "        [ 0.0869,  0.2110,  0.3642,  ..., -0.2941,  0.1863,  0.0749],\n",
      "        [ 0.0328,  0.0576,  0.0036,  ..., -0.3382,  0.3109,  0.2312]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 0.2145,  0.0138,  0.2159,  ..., -0.1874, -0.3421, -0.0052],\n",
      "        [ 0.1664, -0.1602,  0.3561,  ..., -0.3209, -0.2472,  0.0517],\n",
      "        [ 0.1601, -0.1517,  0.2886,  ..., -0.2874, -0.3364,  0.0330],\n",
      "        ...,\n",
      "        [ 0.1187, -0.0902,  0.3227,  ..., -0.2334, -0.3442, -0.0601],\n",
      "        [ 0.2408, -0.0955,  0.2090,  ..., -0.2491, -0.2936,  0.0224],\n",
      "        [ 0.2438,  0.0500,  0.2413,  ..., -0.1353, -0.3078, -0.0842]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward>)\n",
      "tensor(14244.6260, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "ep  1:  11%|█         | 3/28 [00:11<01:36,  3.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1467,  0.1756,  0.0402,  ..., -0.2999,  0.2433,  0.2089],\n",
      "        [ 0.0563,  0.1418,  0.1762,  ..., -0.2989,  0.1550,  0.0309],\n",
      "        [ 0.0502,  0.0938,  0.1868,  ..., -0.2943,  0.2382,  0.0758],\n",
      "        ...,\n",
      "        [-0.0173,  0.1722,  0.1765,  ..., -0.2861,  0.3367,  0.1425],\n",
      "        [-0.0705,  0.1652,  0.3381,  ..., -0.2891,  0.1791,  0.1993],\n",
      "        [ 0.1203,  0.0419,  0.4789,  ..., -0.0901,  0.0998,  0.1019]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 0.1485, -0.0433,  0.3751,  ..., -0.3541, -0.3148, -0.1854],\n",
      "        [ 0.1732, -0.0780,  0.3524,  ..., -0.2841, -0.2535,  0.1884],\n",
      "        [ 0.1508, -0.0391,  0.2202,  ..., -0.2506, -0.3051,  0.0177],\n",
      "        ...,\n",
      "        [ 0.1559, -0.0663,  0.3251,  ..., -0.2631, -0.2227,  0.0214],\n",
      "        [ 0.1890,  0.0935,  0.1782,  ..., -0.2004, -0.2612, -0.0571],\n",
      "        [ 0.1932, -0.0474,  0.1989,  ..., -0.2249, -0.2516,  0.0493]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward>)\n",
      "tensor(75547624., device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "ep  1:  14%|█▍        | 4/28 [00:15<01:32,  3.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0231,  0.0695,  0.3479,  ..., -0.2291,  0.1403,  0.0182],\n",
      "        [-0.0620,  0.2309, -0.0333,  ..., -0.4138,  0.3357,  0.1346],\n",
      "        [-0.0225,  0.1090,  0.2486,  ..., -0.2101,  0.1970, -0.0440],\n",
      "        ...,\n",
      "        [ 0.0351, -0.0560,  0.3379,  ..., -0.0970,  0.0276,  0.1317],\n",
      "        [ 0.0344,  0.0331,  0.2794,  ..., -0.2025,  0.1657,  0.1602],\n",
      "        [ 0.1264,  0.0237,  0.3267,  ..., -0.1974,  0.1912,  0.1050]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 1., -1.,  1.,  ...,  1., -1., -1.],\n",
      "        [ 1., -1.,  1.,  ...,  1., -1., -1.],\n",
      "        [ 1., -1.,  1.,  ...,  1., -1., -1.],\n",
      "        ...,\n",
      "        [ 1., -1.,  1.,  ...,  1., -1., -1.],\n",
      "        [ 1., -1.,  1.,  ...,  1., -1., -1.],\n",
      "        [ 1., -1.,  1.,  ...,  1., -1., -1.]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward>)\n",
      "tensor(2.0270e+15, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "ep  1:  18%|█▊        | 5/28 [00:19<01:28,  3.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0736,  0.1307,  0.2086,  ..., -0.4036,  0.2623,  0.1591],\n",
      "        [ 0.0649,  0.1284,  0.0900,  ..., -0.2708,  0.2072,  0.1988],\n",
      "        [ 0.0283,  0.1098,  0.2476,  ..., -0.2765,  0.2070,  0.0937],\n",
      "        ...,\n",
      "        [-0.0223,  0.1586,  0.1503,  ..., -0.3481,  0.3078,  0.1897],\n",
      "        [-0.0507,  0.2048,  0.0374,  ..., -0.2438,  0.3101,  0.0294],\n",
      "        [ 0.3009, -0.3155,  0.4283,  ...,  0.2845,  0.1838,  0.3308]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 1., -1.,  1.,  ...,  1., -1., -1.],\n",
      "        [ 1., -1.,  1.,  ...,  1., -1., -1.],\n",
      "        [ 1., -1.,  1.,  ...,  1., -1., -1.],\n",
      "        ...,\n",
      "        [ 1., -1.,  1.,  ...,  1., -1., -1.],\n",
      "        [ 1., -1.,  1.,  ...,  1., -1., -1.],\n",
      "        [ 1., -1.,  1.,  ...,  1., -1., -1.]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward>)\n",
      "tensor(7.0649e+29, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "ep  1:  21%|██▏       | 6/28 [00:23<01:24,  3.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1222, -0.0125, -0.0975,  ..., -0.1493,  0.3086,  0.3336],\n",
      "        [ 0.0158,  0.0928, -0.0326,  ..., -0.3675,  0.2282,  0.2922],\n",
      "        [ 0.1206, -0.0533,  0.1103,  ..., -0.0772,  0.3654,  0.2117],\n",
      "        ...,\n",
      "        [ 0.3317,  0.2781, -0.2040,  ..., -0.0864,  0.2765,  0.5427],\n",
      "        [ 0.2506, -0.0282,  0.2501,  ..., -0.2563,  0.2408,  0.0518],\n",
      "        [ 0.0643,  0.0836,  0.0956,  ..., -0.2507,  0.1690,  0.2622]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 1., -1.,  1.,  ...,  1., -1., -1.],\n",
      "        [ 1., -1.,  1.,  ...,  1., -1., -1.],\n",
      "        [ 1., -1.,  1.,  ...,  1., -1., -1.],\n",
      "        ...,\n",
      "        [ 1., -1.,  1.,  ...,  1., -1., -1.],\n",
      "        [ 1., -1.,  1.,  ...,  1., -1., -1.],\n",
      "        [ 1., -1.,  1.,  ...,  1., -1., -1.]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep  1:  21%|██▏       | 6/28 [00:26<01:38,  4.48s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-27588f2b8bea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_train_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ep {:2d}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mtext_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_input_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m# train step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-9871ed560bed>\u001b[0m in \u001b[0;36mmake_input_batch\u001b[0;34m(i_batch, df, batch_size)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mtext_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtext_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_hidden_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mother_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (batch_size, 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mother_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mtrain_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# save path\n",
    "config = f'hid-{hidden_size}-numlin-{num_linear}'\n",
    "print(config)\n",
    "save_path = data_dir + '/results/' + config\n",
    "\n",
    "# model design\n",
    "model = Model(hidden_size=hidden_size, num_linear=num_linear)\n",
    "# if os.path.isfile(save_path + '/model.pt'):\n",
    "#     model.load_state_dict(torch.load(save_path + '/model.pt'))\n",
    "model.to(device)\n",
    "\n",
    "# Learning Rate\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "lmbda = lambda epoch: 0.95\n",
    "scheduler = MultiplicativeLR(optimizer, lr_lambda=lmbda)\n",
    "total_acc = 0\n",
    "print(total_acc)\n",
    "losses, acc_train, acc_valid = [], [], []\n",
    "print(\"Start Training\")\n",
    "for epoch in range(num_epochs):\n",
    "    # train\n",
    "    running_loss = 0.0\n",
    "    total_acc = 0\n",
    "    model.train()\n",
    "\n",
    "    # shuffle train data\n",
    "    train_df = train_df.sample(frac=1, random_state=epoch).reset_index(drop=True)\n",
    "\n",
    "    for i_batch in trange(num_train_batches, desc='ep {:2d}'.format(epoch + 1)):\n",
    "        text_embeddings, other_inputs, train_labels = make_input_batch(i_batch, train_df, batch_size)\n",
    "\n",
    "        # train step\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(text_embeddings, other_inputs)\n",
    "        \n",
    "        loss = criterion(outputs, train_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # record\n",
    "        losses.append(loss.cpu().detach().item())\n",
    "        running_loss += losses[-1]\n",
    "        predictions = compute_predictions(outputs)\n",
    "        total_acc += (predictions == train_labels).sum().item()\n",
    "\n",
    "    print(' loss: %.6f,  train acc: %.6f' % (running_loss / len(train_df), total_acc / len(train_df)))\n",
    "    acc_train.append(total_acc / len(train_df))\n",
    "    scheduler.step()\n",
    "\n",
    "    # validate\n",
    "    if epoch % 3 == 0:\n",
    "        model.eval()\n",
    "        total_acc = 0\n",
    "        ## need to find valid data\n",
    "        with torch.no_grad():\n",
    "            for i_batch in trange(num_valid_batches, desc='valid'):\n",
    "                text_embeddings, other_inputs, valid_labels = make_input_batch(i_batch, valid_df, batch_size)\n",
    "                outputs = model(text_embeddings, other_inputs)\n",
    "                predictions = compute_predictions(outputs)\n",
    "                total_acc += (predictions == valid_labels).sum().item()\n",
    "\n",
    "        print('valid acc', total_acc / len(valid_df))\n",
    "        acc_valid.append(total_acc / len(valid_df))\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "if not os.path.isdir(save_path):\n",
    "    os.mkdir(save_path)\n",
    "torch.save(model.state_dict(), save_path + '/model.pt')\n",
    "\n",
    "record = json.dumps({\n",
    "    'losses' : losses, 'acc_train' : acc_train, 'acc_valid' : acc_valid, \n",
    "    'num_epochs' : num_epochs, 'batch_size' : batch_size, 'lr' : lr, 'hidden_size':hidden_size, 'num_linear':num_linear,\n",
    "    'transformer_tag' : transformer_tag\n",
    "}, sort_keys=True, indent=4)\n",
    "records.append(record)\n",
    "with open(save_path + f'/record-{num_epochs}.json', 'w') as f:\n",
    "    f.write(record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records_p = data_dir + f'results/records-{num_epochs}.json'\n",
    "\n",
    "with open(records_p, 'r') as f:\n",
    "    records = json.loads(f.read())\n",
    "records = [json.loads(record) for record in records]\n",
    "records = {(r['hidden_size'], r['num_linear']) : r for r in records}\n",
    "\n",
    "fig, axs = plt.subplots(len(hidden_sizes), len(num_linears), sharex=True, sharey=True, figsize=(12,8))\n",
    "axs = axs if len(hidden_sizes) == 1 and len(num_linears) == 1 else axs[ihs, inl]\n",
    "for ihs, hidden_size in enumerate(hidden_sizes):\n",
    "    for inl, num_linear in enumerate(num_linears):\n",
    "        r = records[(hidden_size, num_linear)]\n",
    "        axs.plot([i for i in range(num_epochs)], r['acc_train'])\n",
    "        axs.plot([i for i in range(0, num_epochs, 3)], r['acc_valid'], 'tab:orange')\n",
    "        axs.set_title('hs={}, nl={} ({:.1f})'.format(hidden_size, num_linear, r['acc_valid'][-1]*100))\n",
    "\n",
    "# for ax in axs.flat:\n",
    "#     ax.set(xlabel='epochs', ylabel='accuracy')\n",
    "#     # Hide x labels and tick labels for top plots and y ticks for right plots.\n",
    "#     ax.label_outer()\n",
    "\n",
    "fig.savefig(data_dir + f'results/plt-{num_epochs}.png')\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
